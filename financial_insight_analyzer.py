"""
ì¬ë¬´ì œí‘œ AI ì¸ì‚¬ì´íŠ¸ ë¶„ì„ê¸°

LLMì„ í™œìš©í•˜ì—¬ ì¬ë¬´ì œí‘œì˜ ì´ìƒ íŒ¨í„´ì„ ê°ì§€í•˜ê³ ,
ê²€ìƒ‰ì„ í†µí•´ ì›ì¸ì„ íŒŒì•…í•˜ì—¬ ì¢…í•© ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì•„í‚¤í…ì²˜:
1. LLM 0 (Flash): ì—…ì¢… íŒŒì•…
2. LLM 1 (Pro): ì´ìƒ ê°ì§€
3. ë³‘ë ¬ ì›¹ ë¦¬ì„œì¹˜ (Pro + Search): í…œí”Œë¦¿ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ë¡œ ê²€ìƒ‰ ì‹¤í–‰
4. LLM 2 (Pro): ì¢…í•© ë³´ê³ 
"""

import os
import json
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from dotenv import load_dotenv

# Gemini API
from google import genai
from google.genai import types

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))

# ëª¨ë¸ ì„¤ì •
MODEL_PRO = "gemini-2.5-pro"  # Pro ëª¨ë¸ (ë¶„ì„ìš©)
MODEL_FLASH = "gemini-2.5-flash"  # Flash ëª¨ë¸ (ë¹ ë¥¸ ì²˜ë¦¬)
MODEL_RESEARCH = "gemini-2.5-pro"  # ë¦¬ì„œì¹˜ ëª¨ë¸ (ê²€ìƒ‰ + ë¶„ì„)


@dataclass
class Anomaly:
    """ê°ì§€ëœ ì´ìƒ íŒ¨í„´"""
    period: str         # "FY2024" ë˜ëŠ” "FY2020-FY2024"
    item: str           # ì´ìƒ í•­ëª©ëª…
    finding: str        # ìˆ˜ì¹˜ì™€ ë³€í™” (ì‚¬ì‹¤ë§Œ)
    context: str        # ê´€ë ¨ í•­ëª© ìˆ˜ì¹˜
    search_queries: List[str] = None  # ì›ì¸ ì¶”ì  ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸ (ê²€ìƒ‰ì–´ ìƒì„± ì—ì´ì „íŠ¸ê°€ ì±„ì›€)


@dataclass
class SearchTask:
    """ê²€ìƒ‰ íƒœìŠ¤í¬"""
    anomaly: Anomaly
    query_type: str  # company, industry, macro, competitor
    query: str


@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼"""
    task: SearchTask
    result: str
    sources: List[str]


class FinancialInsightAnalyzer:
    """ì¬ë¬´ì œí‘œ AI ì¸ì‚¬ì´íŠ¸ ë¶„ì„ê¸°"""

    def __init__(self):
        self.client = client

    async def analyze(
        self,
        financial_data: Dict[str, Any],
        company_info: Dict[str, Any],
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            financial_data: ì¬ë¬´ì œí‘œ ë°ì´í„° (bs, is, vcm ë“±)
            company_info: ê¸°ì—…ê°œí™©ì •ë³´
            progress_callback: ì§„í–‰ ìƒíƒœ ì½œë°± í•¨ìˆ˜ (progress, message)

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        def update(progress: int, message: str):
            if progress_callback:
                progress_callback(progress, message)
            print(f"[{progress}%] {message}")

        company_name = company_info.get('corp_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
        print(f"\n{'='*60}")
        print(f"[ë¶„ì„ ì‹œì‘] {company_name}")
        print(f"{'='*60}")

        # 1ë‹¨ê³„: ì—…ì¢… íŒŒì•… (Flash + Search)
        update(10, f'[1/5] ì—…ì¢… íŒŒì•… ì¤‘ - {company_name}')
        industry_info = await self._identify_industry(company_info)
        print(f"  â†’ ì—…ì¢…: {industry_info.get('industry', 'íŒŒì•… ì‹¤íŒ¨')}")

        # 2ë‹¨ê³„: ì´ìƒ ê°ì§€ (Pro)
        update(20, '[2/5] ì¬ë¬´ì œí‘œ ì´ìƒ íŒ¨í„´ ê°ì§€ ì¤‘')
        anomalies = await self._detect_anomalies(financial_data, company_info, industry_info)
        print(f"  â†’ ê°ì§€ëœ ì´ìƒ íŒ¨í„´: {len(anomalies)}ê°œ")

        if not anomalies:
            update(100, 'ë¶„ì„ ì™„ë£Œ - ì´ìƒ íŒ¨í„´ ì—†ìŒ')
            return {
                "success": False,
                "no_anomalies": True,
                "company_name": company_name,
                "industry_info": industry_info,
                "anomalies": [],
                "insights": "ì´ìƒ íŒ¨í„´ ê°ì§€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "report": None,
                "error": "ì´ìƒ íŒ¨í„´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. AI ë¶„ì„ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            }

        # 3ë‹¨ê³„: ì›ì¸ ì¶”ì  ê²€ìƒ‰ì–´ ìƒì„± (Pro)
        update(30, f'[3/5] ì›ì¸ ì¶”ì  ê²€ìƒ‰ì–´ ìƒì„± ì¤‘ - {len(anomalies)}ê°œ íŒ¨í„´')
        anomalies = await self._generate_search_queries(anomalies, company_info, industry_info)

        # 4ë‹¨ê³„: ì´ìƒ íŒ¨í„´ë³„ ì›¹ ë¦¬ì„œì¹˜ ë³‘ë ¬ ì‹¤í–‰ (Pro+Search)
        update(45, f'[4/5] ì›¹ ë¦¬ì„œì¹˜ ì§„í–‰ ì¤‘ - {len(anomalies)}ê°œ ë³‘ë ¬ ë¶„ì„')
        search_results = await self._execute_parallel_research(anomalies, company_info, industry_info)
        print(f"  â†’ ì™„ë£Œëœ ë¦¬ì„œì¹˜: {len(search_results)}ê°œ")

        # 5ë‹¨ê³„: ì¢…í•© ë³´ê³ ì„œ ìƒì„± (Pro)
        update(80, '[5/5] ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì¤‘')
        report = await self._generate_report(
            financial_data, company_info, industry_info,
            anomalies, search_results
        )

        update(95, 'ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ')
        print(f"\n{'='*60}")
        print(f"[ë¶„ì„ ì™„ë£Œ] {company_name}")
        print(f"{'='*60}")

        return {
            "success": True,
            "company_name": company_name,
            "industry_info": industry_info,
            "anomalies": [asdict(a) for a in anomalies],
            "search_results": [
                {
                    "query": sr.task.query,
                    "query_type": sr.task.query_type,
                    "result": sr.result,
                    "sources": sr.sources
                }
                for sr in search_results
            ],
            "report": report
        }

    async def _identify_industry(self, company_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì—…ì¢… íŒŒì•… (Google Search í™œìš©)
        """
        company_name = company_info.get('corp_name', '')
        induty_code = company_info.get('induty_code', '')

        prompt = f"""
ë‹¤ìŒ íšŒì‚¬ì˜ ì—…ì¢…ê³¼ ì‚¬ì—… ë‚´ìš©ì„ íŒŒì•…í•´ì£¼ì„¸ìš”.

íšŒì‚¬ëª…: {company_name}
ì—…ì¢…ì½”ë“œ: {induty_code}

ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{{
    "industry": "ì£¼ìš” ì—…ì¢… (ì˜ˆ: ì˜¤í”¼ìŠ¤ ê°€êµ¬ ì œì¡°ì—…)",
    "business_description": "ì‚¬ì—… ë‚´ìš© ê°„ë‹¨ ì„¤ëª…",
    "industry_keywords": ["ì—…ì¢… ê´€ë ¨ í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...],
    "competitors": ["ì£¼ìš” ê²½ìŸì‚¬1", "ê²½ìŸì‚¬2", ...],
    "macro_factors": ["ê±°ì‹œê²½ì œ ì˜í–¥ ìš”ì¸1", "ìš”ì¸2", ...]
}}
"""

        try:
            # Flash ëª¨ë¸ + Searchë¡œ ë¹ ë¥´ê²Œ ì—…ì¢… íŒŒì•…
            response = self.client.models.generate_content(
                model=MODEL_FLASH,
                contents=prompt,
                config=types.GenerateContentConfig(
                    tools=[types.Tool(google_search=types.GoogleSearch())]
                )
            )

            # JSON íŒŒì‹± ì‹œë„
            result_text = response.text
            # JSON ë¸”ë¡ ì¶”ì¶œ
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]

            return json.loads(result_text.strip())

        except Exception as e:
            print(f"  [ê²½ê³ ] ì—…ì¢… íŒŒì•… ì‹¤íŒ¨: {e}")
            return {
                "industry": "íŒŒì•… ì‹¤íŒ¨",
                "business_description": "",
                "industry_keywords": [],
                "competitors": [],
                "macro_factors": []
            }

    async def _detect_anomalies(
        self,
        financial_data: Dict[str, Any],
        company_info: Dict[str, Any],
        industry_info: Dict[str, Any]
    ) -> List[Anomaly]:
        """
        ì´ìƒ íŒ¨í„´ ê°ì§€ (Pro ëª¨ë¸)
        """
        company_name = company_info.get('corp_name', '')

        # ì¬ë¬´ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        financial_summary = self._format_financial_data(financial_data)

        prompt = f"""
ë‹¹ì‹ ì€ PE(ì‚¬ëª¨í€ë“œ)ì˜ M&A ì‹¤ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì¬ë¬´ì œí‘œë¥¼ ë¶„ì„í•˜ì—¬ ì¸ìˆ˜ ê²€í†  ì‹œ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  ëª¨ë“  ì´ìƒ ì§•í›„ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

## íšŒì‚¬ ì •ë³´
- íšŒì‚¬ëª…: {company_name}
- ì—…ì¢…: {industry_info.get('industry', 'ì•Œ ìˆ˜ ì—†ìŒ')}
- ì‚¬ì—…: {industry_info.get('business_description', '')}

## ì¬ë¬´ ë°ì´í„°
{financial_summary}

## ë¶„ì„ ê´€ì 

M&A ì‹¤ì‚¬ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ì–‘í•œ ì‹œê°ì—ì„œ ì´ìƒ ì§•í›„ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.
ì•„ë˜ëŠ” ì˜ˆì‹œì¼ ë¿ì´ë©°, ì´ ì™¸ì—ë„ ë°œê²¬ë˜ëŠ” ëª¨ë“  ì´ìƒ íŒ¨í„´ì„ ë³´ê³ í•´ì£¼ì„¸ìš”.

### A. ì†ìµê³„ì‚°ì„œ(IS) ë¶„ì„ ì˜ˆì‹œ
- ë§¤ì¶œ/ì˜ì—…ì´ìµ/ë‹¹ê¸°ìˆœì´ìµ ê¸‰ë³€ë™, í‘ìâ†”ì ì ì „í™˜
- ë§¤ì¶œì›ê°€ìœ¨/íŒê´€ë¹„ìœ¨ ì´ìƒ ë³€ë™
- ì˜ì—…ì™¸ìˆ˜ìµ/ë¹„ìš© ê¸‰ì¦ (ì¼íšŒì„± í•­ëª©)
- íŠ¹ì • ë¹„ìš© í•­ëª© ì´ìƒ (ì¸ê±´ë¹„, ëŒ€ì†ìƒê°ë¹„ ë“±)

### B. ì¬ë¬´ìƒíƒœí‘œ(BS) ë¶„ì„ ì˜ˆì‹œ
- ìì‚°/ë¶€ì±„ êµ¬ì¡° ê¸‰ë³€, ë¶€ì±„ë¹„ìœ¨ ì´ìƒ
- ìë³¸ì ì‹, ëˆ„ì ê²°ì†ê¸ˆ ì‹¬í™”
- ë§¤ì¶œì±„ê¶Œ/ì¬ê³ ìì‚° ê¸‰ì¦ (ë¶€ì‹¤ ì§•í›„)
- ì¶©ë‹¹ë¶€ì±„/ìš°ë°œë¶€ì±„ ê¸‰ì¦ (ìˆ¨ê²¨ì§„ ë¦¬ìŠ¤í¬)

### C. í˜„ê¸ˆíë¦„í‘œ(CF) ë¶„ì„ ì˜ˆì‹œ
- ì˜ì—…í˜„ê¸ˆíë¦„ ì ì ì§€ì†
- íˆ¬ì/ì¬ë¬´ í˜„ê¸ˆíë¦„ ì´ìƒ íŒ¨í„´
- í˜„ê¸ˆ ê¸‰ê°

### D. Cross-Check ë¶„ì„ ì˜ˆì‹œ (ì¬ë¬´ì œí‘œ ê°„ ë¹„êµ)
- [ISâ†”BS] ë§¤ì¶œâ†‘ but ë§¤ì¶œì±„ê¶Œ ë” ë¹ ë¥´ê²Œâ†‘ â†’ ë§¤ì¶œ í’ˆì§ˆ ì˜ì‹¬
- [ISâ†”CF] ë‹¹ê¸°ìˆœì´ìµ í‘ì but ì˜ì—…í˜„ê¸ˆíë¦„ ì ì â†’ ì´ìµì˜ ì§ˆ ì˜ì‹¬
- [BSâ†”CF] ì°¨ì…ê¸ˆâ†‘ but ì¬ë¬´CF ë¶ˆì¼ì¹˜ â†’ ìˆ¨ê²¨ì§„ ê±°ë˜
- [ì „ì²´] ë‹¤ë…„ê°„ ì§€ì† íŒ¨í„´ (3ë…„ ì—°ì† ì ì, ìë³¸ì ì‹ ì‹¬í™” ë“±)

ìœ„ ì˜ˆì‹œ ì™¸ì—ë„ PE íˆ¬ìì ê´€ì ì—ì„œ ìš°ë ¤ë˜ëŠ” ëª¨ë“  ì´ìƒ ì§•í›„ë¥¼ ë¹ ì§ì—†ì´ ì°¾ì•„ì£¼ì„¸ìš”.

## ì¶œë ¥ í˜•ì‹
JSON ë°°ì—´ë¡œ ë°˜í™˜:
[
    {{
        "period": "FY2024",
        "item": "ë‹¹ê¸°ìˆœì´ìµ",
        "finding": "130ì–µì› í‘ìì „í™˜ (ì „ë…„ -80ì–µì›, +262%)",
        "context": "ì˜ì—…ì´ìµ 54ì–µì›, ì˜ì—…ì™¸ìˆ˜ìµ 248ì–µì›"
    }},
    {{
        "period": "FY2020-FY2024",
        "item": "ìë³¸ì´ê³„",
        "finding": "5ë…„ ì—°ì† ìë³¸ì ì‹ (-200ì–µ â†’ -527ì–µ)",
        "context": "ëˆ„ì ê²°ì†ê¸ˆ 1,200ì–µì›, ìƒí™˜ì „í™˜ìš°ì„ ì£¼ 800ì–µì›"
    }}
]

ì£¼ì˜ì‚¬í•­:
- period: ë‹¨ì¼ ì—°ë„("FY2024") ë˜ëŠ” ê¸°ê°„("FY2020-FY2024")
- finding: ìˆ˜ì¹˜ì™€ ë³€í™” ì‚¬ì‹¤ë§Œ ê¸°ì¬
- context: ê´€ë ¨ í•­ëª© ìˆ˜ì¹˜
- ì´ìƒ ì§•í›„ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ [] ë°˜í™˜
"""

        try:
            response = self.client.models.generate_content(
                model=MODEL_PRO,
                contents=prompt
            )

            result_text = response.text
            # JSON ë¸”ë¡ ì¶”ì¶œ
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]

            anomalies_data = json.loads(result_text.strip())

            return [
                Anomaly(
                    period=a.get('period', ''),
                    item=a.get('item', ''),
                    finding=a.get('finding', ''),
                    context=a.get('context', '')
                )
                for a in anomalies_data
            ]

        except Exception as e:
            print(f"  [ì˜¤ë¥˜] ì´ìƒ ê°ì§€ ì‹¤íŒ¨: {e}")
            return []

    async def _generate_search_queries(
        self,
        anomalies: List[Anomaly],
        company_info: Dict[str, Any],
        industry_info: Dict[str, Any]
    ) -> List[Anomaly]:
        """
        ì´ìƒ íŒ¨í„´ë³„ ì›ì¸ ì¶”ì  ê²€ìƒ‰ì–´ ìƒì„± (Pro ëª¨ë¸)

        ê° ì´ìƒ íŒ¨í„´ì— ëŒ€í•´ ì›ì¸ì„ ì°¾ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        ì¬ë¬´ ìˆ˜ì¹˜ ìì²´ê°€ ì•„ë‹Œ, ê·¸ ì›ì¸ì´ ë  ìˆ˜ ìˆëŠ” ì‚¬ê±´/ë‰´ìŠ¤ë¥¼ ì°¾ëŠ” ê²€ìƒ‰ì–´ì…ë‹ˆë‹¤.
        """
        company_name = company_info.get('corp_name', '')
        industry = industry_info.get('industry', '')
        competitors = industry_info.get('competitors', [])
        competitors_str = ', '.join(competitors[:3]) if competitors else ''

        # ëª¨ë“  ì´ìƒ íŒ¨í„´ì„ JSONìœ¼ë¡œ êµ¬ì„±
        anomalies_json = json.dumps([
            {
                "period": a.period,
                "item": a.item,
                "finding": a.finding,
                "context": a.context
            }
            for a in anomalies
        ], ensure_ascii=False, indent=2)

        prompt = f"""ë‹¹ì‹ ì€ M&A ì‹¤ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì¬ë¬´ì œí‘œ ì´ìƒ íŒ¨í„´ë“¤ì˜ **ì›ì¸**ì„ ì°¾ê¸° ìœ„í•œ ì›¹ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ì¤‘ìš” ì§€ì¹¨
âš ï¸ **ì¬ë¬´ ìˆ˜ì¹˜ ìì²´ë¥¼ ê²€ìƒ‰í•˜ì§€ ë§ˆì„¸ìš”!** ìš°ë¦¬ëŠ” ì´ë¯¸ ì¬ë¬´ì œí‘œ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
âš ï¸ **ì›ì¸ì´ ë  ìˆ˜ ìˆëŠ” ì‚¬ê±´, ë‰´ìŠ¤, ê³µì‹œë¥¼ ì°¾ëŠ” ê²€ìƒ‰ì–´**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

## íšŒì‚¬ ì •ë³´
- íšŒì‚¬ëª…: {company_name}
- ì—…ì¢…: {industry}
- ì£¼ìš” ê²½ìŸì‚¬: {competitors_str}

## ë¶„ì„ ëŒ€ìƒ ì´ìƒ íŒ¨í„´ë“¤
{anomalies_json}

## ê²€ìƒ‰ì–´ ìƒì„± ê°€ì´ë“œ

### ì˜ëª»ëœ ê²€ìƒ‰ì–´ ì˜ˆì‹œ (âŒ ì‚¬ìš© ê¸ˆì§€)
- "{company_name} 2024ë…„ ì¬ë¬´ì œí‘œ" â†’ ì´ë¯¸ ê°€ì§€ê³  ìˆìŒ
- "{company_name} ë§¤ì¶œì•¡" â†’ ì´ë¯¸ ê°€ì§€ê³  ìˆìŒ
- "{company_name} ì˜ì—…ì´ìµ" â†’ ì´ë¯¸ ê°€ì§€ê³  ìˆìŒ

### ì˜¬ë°”ë¥¸ ê²€ìƒ‰ì–´ ì˜ˆì‹œ (âœ… ì´ëŸ° ë°©í–¥ìœ¼ë¡œ)
**ëŒ€ì†ìƒê°ë¹„ ê¸‰ì¦ì˜ ê²½ìš°:**
- "{company_name} ê±°ë˜ì²˜ ë¶€ë„"
- "{company_name} ì±„ê¶Œ íšŒìˆ˜ ë¬¸ì œ"
- "{industry} ëŒ€ê¸ˆ ì—°ì²´ ì¦ê°€ 2024"
- "{company_name} ì†Œì†¡ íŒ¨ì†Œ"

**ë§¤ì¶œ ê¸‰ê°ì˜ ê²½ìš°:**
- "{company_name} ì£¼ìš” ê³ ê° ì´íƒˆ"
- "{company_name} ê³„ì•½ í•´ì§€"
- "{industry} ìˆ˜ìš” ê°ì†Œ 2024"
- "{company_name} ê²½ìŸ ì‹¬í™”"

**ìœ í˜•ìì‚° ê¸‰ì¦ì˜ ê²½ìš°:**
- "{company_name} ì‹ ê·œ ê³µì¥"
- "{company_name} ì„¤ë¹„ íˆ¬ì"
- "{company_name} ì¸ìˆ˜í•©ë³‘"
- "{company_name} ì‚¬ì—… í™•ì¥"

**ì°¨ì…ê¸ˆ ê¸‰ì¦ì˜ ê²½ìš°:**
- "{company_name} ëŒ€ì¶œ"
- "{company_name} íšŒì‚¬ì±„ ë°œí–‰"
- "{company_name} ìê¸ˆ ì¡°ë‹¬"
- "{company_name} ìœ ë™ì„± ìœ„ê¸°"

## ì¶œë ¥ í˜•ì‹
ê° ì´ìƒ íŒ¨í„´ì— ëŒ€í•´ **ìµœì†Œ 5ê°œ ì´ìƒ**ì˜ ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”.
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:

```json
[
    {{
        "period": "FY2024",
        "item": "ëŒ€ì†ìƒê°ë¹„",
        "search_queries": [
            "{company_name} ê±°ë˜ì²˜ ë¶€ë„ 2024",
            "{company_name} ì±„ê¶Œ íšŒìˆ˜ ì‹¤íŒ¨",
            "{company_name} ë§¤ì¶œì±„ê¶Œ ì†ìƒ",
            "{industry} ëŒ€ê¸ˆ ì—°ì²´ìœ¨ 2024",
            "{company_name} ì†Œì†¡ ì†í•´ë°°ìƒ",
            "..."
        ]
    }},
    ...
]
```

ëª¨ë“  ì´ìƒ íŒ¨í„´ì— ëŒ€í•´ ë¹ ì§ì—†ì´ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”."""

        try:
            print(f"  [ê²€ìƒ‰ì–´ ìƒì„± ì‹œì‘] {len(anomalies)}ê°œ ì´ìƒ íŒ¨í„´")

            response = self.client.models.generate_content(
                model=MODEL_PRO,
                contents=prompt
            )

            result_text = response.text

            # JSON íŒŒì‹±
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]

            queries_data = json.loads(result_text.strip())

            # ìƒì„±ëœ ê²€ìƒ‰ì–´ë¥¼ Anomaly ê°ì²´ì— ë§¤í•‘
            queries_map = {
                (q['period'], q['item']): q.get('search_queries', [])
                for q in queries_data
            }

            for anomaly in anomalies:
                key = (anomaly.period, anomaly.item)
                anomaly.search_queries = queries_map.get(key, [])
                print(f"    â†’ {anomaly.item}: {len(anomaly.search_queries)}ê°œ ê²€ìƒ‰ì–´ ìƒì„±")

            total_queries = sum(len(a.search_queries or []) for a in anomalies)
            print(f"  [ê²€ìƒ‰ì–´ ìƒì„± ì™„ë£Œ] ì´ {total_queries}ê°œ ê²€ìƒ‰ì–´")

            return anomalies

        except Exception as e:
            print(f"  [ì˜¤ë¥˜] ê²€ìƒ‰ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²€ìƒ‰ì–´ ì„¤ì •
            for anomaly in anomalies:
                year = anomaly.period.replace('FY', '').split('-')[-1] if anomaly.period else ''
                anomaly.search_queries = [
                    f"{company_name} {anomaly.item} {year}",
                    f"{company_name} {year}ë…„ ì£¼ìš” ì´ìŠˆ",
                    f"{industry} {year}ë…„ ë™í–¥"
                ]
            return anomalies

    def _build_research_prompt(
        self,
        anomaly: Anomaly,
        company_info: Dict[str, Any],
        industry_info: Dict[str, Any]
    ) -> str:
        """
        ì´ìƒ íŒ¨í„´ë³„ ì›¹ ë¦¬ì„œì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìƒì„±ëœ ê²€ìƒ‰ì–´ ì‚¬ìš©)
        """
        company_name = company_info.get('corp_name', '')
        industry = industry_info.get('industry', '')

        # ìƒì„±ëœ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸ í¬ë§·íŒ…
        search_queries = anomaly.search_queries or []
        search_queries_str = "\n".join([f"- {q}" for q in search_queries]) if search_queries else "- (ê²€ìƒ‰ì–´ ì—†ìŒ)"

        research_prompt = f"""ë‹¹ì‹ ì€ M&A ì‹¤ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì¬ë¬´ì œí‘œ ì´ìƒ íŒ¨í„´ì˜ **ì›ì¸**ì„ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì¡°ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤.

## [ì ˆëŒ€ ê·œì¹™] ì‚¬ì‹¤ ê¸°ë°˜ ì‘ë‹µë§Œ í—ˆìš©
ğŸš« **ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­:**
- ê²€ìƒ‰ ê²°ê³¼ ì—†ì´ ì¶”ì¸¡í•˜ê±°ë‚˜ ê°€ì •í•˜ëŠ” ê²ƒ
- "~ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤", "~ë¡œ ì¶”ì •ë©ë‹ˆë‹¤" ê°™ì€ ì¶”ë¡ 
- ì‚¬ì „ í•™ìŠµëœ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ê²ƒ
- ê²€ìƒ‰ì—ì„œ ì°¾ì§€ ëª»í•œ ë‚´ìš©ì„ ë§ˆì¹˜ ì°¾ì€ ê²ƒì²˜ëŸ¼ ì‘ì„±í•˜ëŠ” ê²ƒ

âœ… **ë°˜ë“œì‹œ ì¤€ìˆ˜:**
- ì˜¤ì§ ì›¹ ê²€ìƒ‰ì—ì„œ ì°¾ì€ **ì‹¤ì œ ë‰´ìŠ¤/ê¸°ì‚¬/ê³µì‹œ ë‚´ìš©ë§Œ** ì¸ìš©
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ "ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ
- ëª¨ë“  ë‚´ìš©ì— ì¶œì²˜(ê¸°ì‚¬ ì œëª©, ë‚ ì§œ, ë§¤ì²´)ë¥¼ ëª…ì‹œ

## [í•„ìˆ˜] ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ì§€ì¹¨
âš ï¸ **ë°˜ë“œì‹œ Google Search ë„êµ¬ë¡œ ì•„ë˜ ê²€ìƒ‰ì–´ë“¤ì„ ì‹¤ì œë¡œ ê²€ìƒ‰í•˜ì„¸ìš”.**
âš ï¸ **ì¬ë¬´ ìˆ˜ì¹˜ ê²€ìƒ‰ ê¸ˆì§€!** ì´ë¯¸ ì¬ë¬´ì œí‘œ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

## íšŒì‚¬ ì •ë³´
- íšŒì‚¬ëª…: {company_name}
- ì—…ì¢…: {industry}

## ë¶„ì„ ëŒ€ìƒ ì´ìƒ íŒ¨í„´
- ê¸°ê°„: {anomaly.period}
- í•­ëª©: {anomaly.item}
- ë°œê²¬ ì‚¬ì‹¤: {anomaly.finding}
- ê´€ë ¨ í•­ëª©: {anomaly.context}

## â­ í•„ìˆ˜ ê²€ìƒ‰ì–´ (ì•„ë˜ ê²€ìƒ‰ì–´ë“¤ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”)
{search_queries_str}

## ì¶œë ¥ í˜•ì‹ (ì—„ê²©íˆ ì¤€ìˆ˜)

### ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
[ì›¹ ê²€ìƒ‰ì—ì„œ ì°¾ì€ **ì‹¤ì œ** ë‰´ìŠ¤/ê¸°ì‚¬/ê³µì‹œ ë‚´ìš©ë§Œ ìš”ì•½]
- ë°˜ë“œì‹œ ê²€ìƒ‰ì—ì„œ ì°¾ì€ ì‚¬ì‹¤ë§Œ ê¸°ì¬
- ì°¾ì§€ ëª»í•œ ë‚´ìš©ì€ "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•¨"ìœ¼ë¡œ ëª…ì‹œ

### ì¶œì²˜ (í•„ìˆ˜)
- ì¶œì²˜1: [ê¸°ì‚¬ ì œëª©] - [ë§¤ì²´ëª…] ([ë‚ ì§œ])
- ì¶œì²˜2: [ê¸°ì‚¬ ì œëª©] - [ë§¤ì²´ëª…] ([ë‚ ì§œ])
â€» ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ "ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê´€ë ¨ ì¶œì²˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤." ëª…ì‹œ

### ë¶„ì„ ê²°ë¡ 
[ê²€ìƒ‰ ê²°ê³¼ì— ê¸°ë°˜í•œ ì‚¬ì‹¤ë§Œ ê¸°ì¬. ì¶”ì¸¡ ì ˆëŒ€ ê¸ˆì§€]

âš ï¸ **ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°**: ë°˜ë“œì‹œ "í•´ë‹¹ ì´ìƒ íŒ¨í„´ì˜ ì›ì¸ì„ ì„¤ëª…í•˜ëŠ” ë‰´ìŠ¤ë‚˜ ê³µì‹œë¥¼ ì›¹ ê²€ìƒ‰ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”."""

        return research_prompt

    async def _execute_parallel_research(
        self,
        anomalies: List[Anomaly],
        company_info: Dict[str, Any],
        industry_info: Dict[str, Any]
    ) -> List[SearchResult]:
        """
        ì´ìƒ íŒ¨í„´ë³„ ì›¹ ë¦¬ì„œì¹˜ ë³‘ë ¬ ì‹¤í–‰

        ê° ì´ìƒ íŒ¨í„´ì— ëŒ€í•´:
        1. í…œí”Œë¦¿ ê¸°ë°˜ ë¦¬ì„œì¹˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        2. Pro + Searchë¡œ ì‹¤ì œ ì›¹ ë¦¬ì„œì¹˜ ìˆ˜í–‰

        ëª¨ë“  ì´ìƒ íŒ¨í„´ì€ ë³‘ë ¬ë¡œ ì²˜ë¦¬ë¨
        """
        def extract_sources(response) -> List[str]:
            """ì‘ë‹µì—ì„œ ì†ŒìŠ¤ URL ì¶”ì¶œ"""
            sources = []
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'grounding_metadata'):
                    metadata = candidate.grounding_metadata
                    if hasattr(metadata, 'grounding_chunks') and metadata.grounding_chunks:
                        for chunk in metadata.grounding_chunks:
                            if hasattr(chunk, 'web') and hasattr(chunk.web, 'uri'):
                                sources.append(chunk.web.uri)
            return sources

        def build_fallback_prompt(anomaly: Anomaly) -> str:
            """ì†ŒìŠ¤ ì—†ì„ ë•Œ ì‚¬ìš©í•  ëŒ€ì²´ ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸"""
            company_name = company_info.get('corp_name', '')
            industry = industry_info.get('industry', '')

            # ë” ë„“ì€ ë²”ìœ„ì˜ ëŒ€ì²´ ê²€ìƒ‰ì–´
            year = anomaly.period.replace('FY', '')
            fallback_queries = [
                f"{company_name} {year}ë…„ ë‰´ìŠ¤",
                f"{company_name} {year}ë…„ ì‹¤ì  ë°œí‘œ",
                f"{company_name} ê²½ì˜ ì´ìŠˆ",
                f"{company_name} ì‚¬ì—… í˜„í™©",
                f"{industry} {year}ë…„ ë™í–¥",
                f"{industry} ì—…ê³„ ë‰´ìŠ¤ {year}",
            ]
            queries_str = "\n".join([f"- {q}" for q in fallback_queries])

            return f"""ë‹¹ì‹ ì€ M&A ì‹¤ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ íšŒì‚¬ì˜ ì¬ë¬´ ì´ìƒ íŒ¨í„´ ì›ì¸ì„ ë„“ì€ ë²”ìœ„ì—ì„œ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì¡°ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤.

## [ì ˆëŒ€ ê·œì¹™] ë°˜ë“œì‹œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
âš ï¸ **Google Search ë„êµ¬ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”.**
âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ì´ ì‘ë‹µí•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.

## íšŒì‚¬ ì •ë³´
- íšŒì‚¬ëª…: {company_name}
- ì—…ì¢…: {industry}

## ë¶„ì„ ëŒ€ìƒ
- ê¸°ê°„: {anomaly.period}
- í•­ëª©: {anomaly.item}
- ë°œê²¬ ì‚¬ì‹¤: {anomaly.finding}

## â­ ëŒ€ì²´ ê²€ìƒ‰ì–´ (ë°˜ë“œì‹œ ê²€ìƒ‰)
{queries_str}

## ì¶œë ¥ í˜•ì‹
### ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
[ì›¹ ê²€ìƒ‰ì—ì„œ ì°¾ì€ íšŒì‚¬ ê´€ë ¨ ë‰´ìŠ¤/ê¸°ì‚¬ ë‚´ìš©]

### ì¶œì²˜
- ì¶œì²˜1: [ê¸°ì‚¬ ì œëª©] - [ë§¤ì²´ëª…] ([ë‚ ì§œ])

### ë¶„ì„ ê²°ë¡ 
[ê²€ìƒ‰ ê²°ê³¼ì— ê¸°ë°˜í•œ ë¶„ì„ - ì¶”ì¸¡ ê¸ˆì§€]

âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì „í˜€ ì—†ìœ¼ë©´ "ê´€ë ¨ ì •ë³´ë¥¼ ì›¹ ê²€ìƒ‰ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”."""

        def research_one_sync(anomaly: Anomaly) -> SearchResult:
            """ë™ê¸° í•¨ìˆ˜ë¡œ API í˜¸ì¶œ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰) - Fallback ë¡œì§ í¬í•¨"""
            # 1. ë¦¬ì„œì¹˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            print(f"    [ë¦¬ì„œì¹˜ ì‹œì‘] {anomaly.period} {anomaly.item}")
            prompt = self._build_research_prompt(anomaly, company_info, industry_info)

            # ë”ë¯¸ SearchTask ìƒì„± (ê¸°ì¡´ êµ¬ì¡° í˜¸í™˜ìš©)
            task = SearchTask(
                anomaly=anomaly,
                query_type="integrated",
                query=f"{anomaly.period} {anomaly.item} í†µí•© ë¶„ì„"
            )

            try:
                # 2. Pro + Searchë¡œ ì‹¤ì œ ì›¹ ë¦¬ì„œì¹˜ ìˆ˜í–‰ (1ì°¨ ì‹œë„)
                print(f"    [ì›¹ ë¦¬ì„œì¹˜ ì‹œì‘] {anomaly.period} {anomaly.item}")

                response = self.client.models.generate_content(
                    model=MODEL_RESEARCH,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        tools=[types.Tool(google_search=types.GoogleSearch())]
                    )
                )

                # ì†ŒìŠ¤ URL ì¶”ì¶œ
                sources = extract_sources(response)
                result_text = response.text if response.text else "ê²°ê³¼ ì—†ìŒ"

                # â˜… Fallback ë¡œì§: ì†ŒìŠ¤ê°€ ì—†ìœ¼ë©´ ëŒ€ì²´ ê²€ìƒ‰ì–´ë¡œ ì¬ì‹œë„
                if not sources:
                    print(f"    [Fallback ì‹œì‘] {anomaly.period} {anomaly.item} - ì†ŒìŠ¤ ì—†ìŒ, ëŒ€ì²´ ê²€ìƒ‰ì–´ë¡œ ì¬ì‹œë„")

                    fallback_prompt = build_fallback_prompt(anomaly)
                    fallback_response = self.client.models.generate_content(
                        model=MODEL_RESEARCH,
                        contents=fallback_prompt,
                        config=types.GenerateContentConfig(
                            tools=[types.Tool(google_search=types.GoogleSearch())]
                        )
                    )

                    fallback_sources = extract_sources(fallback_response)
                    fallback_text = fallback_response.text if fallback_response.text else ""

                    if fallback_sources:
                        print(f"    [Fallback ì„±ê³µ] {anomaly.period} {anomaly.item} - {len(fallback_sources)}ê°œ ì†ŒìŠ¤ ë°œê²¬")
                        sources = fallback_sources
                        result_text = f"[ëŒ€ì²´ ê²€ìƒ‰ ê²°ê³¼]\n{fallback_text}"
                    else:
                        print(f"    [Fallback ì‹¤íŒ¨] {anomaly.period} {anomaly.item} - ëŒ€ì²´ ê²€ìƒ‰ë„ ì†ŒìŠ¤ ì—†ìŒ")
                        result_text = f"{result_text}\n\n[ì°¸ê³ : ëŒ€ì²´ ê²€ìƒ‰ë„ ìˆ˜í–‰í–ˆìœ¼ë‚˜ ê´€ë ¨ ì¶œì²˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.]"

                print(f"    [ì›¹ ë¦¬ì„œì¹˜ ì™„ë£Œ] {anomaly.period} {anomaly.item}")
                print(f"    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                print(f"    â”‚ [ë¦¬ì„œì¹˜ ê²°ê³¼] {anomaly.period} {anomaly.item}")
                print(f"    â”‚ ì†ŒìŠ¤: {sources[:3]}")
                print(f"    â”‚ ë‚´ìš© (ì• 500ì):")
                for line in result_text[:500].split('\n'):
                    print(f"    â”‚   {line}")
                print(f"    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

                return SearchResult(
                    task=task,
                    result=result_text,
                    sources=sources[:5]  # ìµœëŒ€ 5ê°œ ì†ŒìŠ¤
                )

            except Exception as e:
                print(f"    [ì›¹ ë¦¬ì„œì¹˜ ì‹¤íŒ¨] {anomaly.period} {anomaly.item}: {e}")
                return SearchResult(
                    task=task,
                    result=f"ë¦¬ì„œì¹˜ ì‹¤íŒ¨: {str(e)}",
                    sources=[]
                )

        # ëª¨ë“  ì´ìƒ íŒ¨í„´ì— ëŒ€í•´ ì™„ì „ ë³‘ë ¬ ì‹¤í–‰ (ThreadPoolExecutor ì‚¬ìš©)
        print(f"  â†’ {len(anomalies)}ê°œ ì´ìƒ íŒ¨í„´ ë³‘ë ¬ ì›¹ ë¦¬ì„œì¹˜ ì‹œì‘ (Pro + Search)")

        loop = asyncio.get_event_loop()
        # ìµœëŒ€ 10ê°œ ìŠ¤ë ˆë“œë¡œ ë™ì‹œ ì‹¤í–‰ ë³´ì¥
        with ThreadPoolExecutor(max_workers=min(len(anomalies), 10)) as executor:
            futures = [loop.run_in_executor(executor, research_one_sync, a) for a in anomalies]
            results = await asyncio.gather(*futures)

        print(f"  â†’ {len(results)}ê°œ ë¦¬ì„œì¹˜ ì™„ë£Œ")
        return list(results)

    async def _generate_report(
        self,
        financial_data: Dict[str, Any],
        company_info: Dict[str, Any],
        industry_info: Dict[str, Any],
        anomalies: List[Anomaly],
        search_results: List[SearchResult]
    ) -> str:
        """
        ì¢…í•© ë³´ê³ ì„œ ìƒì„± (Pro ëª¨ë¸)
        """
        company_name = company_info.get('corp_name', '')

        # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (ì „ì²´ ì „ë‹¬)
        search_summary = ""
        for sr in search_results:
            search_summary += f"\n### {sr.task.query_type}: {sr.task.query}\n"
            search_summary += f"{sr.result}\n"

        anomalies_text = "\n".join([
            f"- {a.period} {a.item}\n  ë°œê²¬: {a.finding}\n  ê´€ë ¨í•­ëª©: {a.context}"
            for a in anomalies
        ])

        prompt = f"""
ë‹¹ì‹ ì€ PE(ì‚¬ëª¨í€ë“œ)ì˜ M&A ì‹¤ì‚¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ íˆ¬ì ê²€í† ìš© ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## íšŒì‚¬ ì •ë³´
- íšŒì‚¬ëª…: {company_name}
- ì—…ì¢…: {industry_info.get('industry', '')}
- ì‚¬ì—…: {industry_info.get('business_description', '')}

## ê°ì§€ëœ ì´ìƒ íŒ¨í„´
{anomalies_text}

## ì¡°ì‚¬ ê²°ê³¼
{search_summary}

## ë³´ê³ ì„œ ì‘ì„± ì§€ì¹¨
1. ê° ì´ìƒ íŒ¨í„´ì— ëŒ€í•´ ì›ì¸ì„ ëª…í™•íˆ ì„¤ëª…
2. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìš”ì•½

## ì¶œë ¥ í˜•ì‹
ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¹ì…˜ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

# {company_name} ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œ

## ìš”ì•½
(3ì¤„ ì´ë‚´ í•µì‹¬ ìš”ì•½)

## ì£¼ìš” ë°œê²¬ì‚¬í•­

### 1. [ë°œê²¬ì‚¬í•­ ì œëª©]
- **í˜„ìƒ**: (ë¬´ì—‡ì´ ë°œìƒí–ˆëŠ”ì§€)
- **ì›ì¸**: (ì™œ ë°œìƒí–ˆëŠ”ì§€)

### 2. [ë°œê²¬ì‚¬í•­ ì œëª©]
- **í˜„ìƒ**: ...
- **ì›ì¸**: ...

(ì´í•˜ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ëª¨ë“  ë°œê²¬ì‚¬í•­ ì‘ì„±)

---
ë³´ê³ ì„œëŠ” ì—¬ê¸°ì„œ ëë‚©ë‹ˆë‹¤. "íˆ¬ì ì‹œì‚¬ì ", "ì¶”ê°€ í™•ì¸ í•„ìš” ì‚¬í•­" ë“± ë‹¤ë¥¸ ì„¹ì…˜ì„ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
"""

        try:
            response = self.client.models.generate_content(
                model=MODEL_PRO,
                contents=prompt
            )
            return response.text

        except Exception as e:
            print(f"  [ì˜¤ë¥˜] ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

    def _format_financial_data(self, financial_data: Dict[str, Any]) -> str:
        """ì¬ë¬´ ë°ì´í„°ë¥¼ ë¶„ì„ìš© ë¬¸ìì—´ë¡œ ë³€í™˜ (ì›ë³¸ ì¬ë¬´ì œí‘œ ì‚¬ìš©)"""
        result = []

        print(f"[FORMAT] financial_data í‚¤: {list(financial_data.keys())}")

        def format_table(data, name: str, max_rows: int = 100) -> None:
            """í…Œì´ë¸” ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜"""
            if data is None:
                return

            print(f"[FORMAT] {name} íƒ€ì…: {type(data)}, ê¸¸ì´: {len(data) if isinstance(data, list) else 'N/A'}")

            if hasattr(data, 'to_string'):
                result.append(f"\n### {name}")
                result.append(data.to_string())
            elif isinstance(data, list) and len(data) > 0:
                result.append(f"\n### {name}")
                if isinstance(data[0], dict):
                    headers = list(data[0].keys())
                    result.append(" | ".join(str(h) for h in headers))
                    result.append("-" * 80)
                    for row in data[:max_rows]:
                        values = [str(row.get(h, '')) for h in headers]
                        result.append(" | ".join(values))

        # ì¬ë¬´ìƒíƒœí‘œ (BS) - ì „ì²´
        format_table(financial_data.get('bs'), 'ì¬ë¬´ìƒíƒœí‘œ', max_rows=100)

        # ì†ìµê³„ì‚°ì„œ (IS ë˜ëŠ” CIS) - ì „ì²´
        is_data = financial_data.get('is') or financial_data.get('cis')
        format_table(is_data, 'ì†ìµê³„ì‚°ì„œ', max_rows=100)

        # í˜„ê¸ˆíë¦„í‘œ (CF) - ì „ì²´
        format_table(financial_data.get('cf'), 'í˜„ê¸ˆíë¦„í‘œ', max_rows=100)

        formatted = "\n".join(result) if result else "ì¬ë¬´ ë°ì´í„° ì—†ìŒ"
        print(f"[FORMAT] ìµœì¢… ë°ì´í„° ê¸¸ì´: {len(formatted)} ë¬¸ì")
        print(f"[FORMAT] ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n{formatted[:500]}...")
        return formatted


# ============================================================
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# ============================================================
async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    analyzer = FinancialInsightAnalyzer()

    # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°
    company_info = {
        "corp_name": "í…ŒìŠ¤íŠ¸ê¸°ì—…",
        "induty_code": "32091"
    }

    financial_data = {
        "vcm": [
            {"í•­ëª©": "ë§¤ì¶œ", "FY2020": 100, "FY2021": 70, "FY2022": 120},
            {"í•­ëª©": "ì˜ì—…ì´ìµ", "FY2020": 10, "FY2021": 5, "FY2022": 15},
        ]
    }

    result = await analyzer.analyze(financial_data, company_info)
    print("\nê²°ê³¼:")
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    asyncio.run(main())
